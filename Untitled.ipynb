{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "71b79710-c046-44e6-9814-9b644628da70",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(tensor([-0.0101, -0.0109], device='cuda:0', grad_fn=<ViewBackward0>),), (tensor([-0.0052, -0.0035], device='cuda:0', grad_fn=<ViewBackward0>),), (tensor([ 0.0028, -0.0085], device='cuda:0', grad_fn=<ViewBackward0>),)]\n",
      "[tensor([-0.0109,  0.0101], device='cuda:0', grad_fn=<FlipBackward0>), tensor([-0.0035,  0.0052], device='cuda:0', grad_fn=<FlipBackward0>), tensor([-0.0085, -0.0028], device='cuda:0', grad_fn=<FlipBackward0>)]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "from HNN import HNN\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "mean = torch.tensor([0.0, 2.0])\n",
    "std = 0.1\n",
    "init_states = (\n",
    "    torch.normal(mean=mean.expand(3, 2), std=std).to(device).requires_grad_()\n",
    ")\n",
    "\n",
    "hnn_model = HNN().to(device)\n",
    "\n",
    "\n",
    "def get_time_derivatives(model, x):\n",
    "    grads_ls = []\n",
    "    for qp_pair in x:\n",
    "        h_hat = model(qp_pair)\n",
    "        grads = torch.autograd.grad(h_hat, qp_pair, create_graph=True)\n",
    "        grads_ls.append(grads)\n",
    "    return grads_ls\n",
    "\n",
    "\n",
    "h_hats = get_time_derivatives(hnn_model, init_states)\n",
    "print(h_hats)\n",
    "\n",
    "\n",
    "def get_deriv_pairs(h_hats):\n",
    "    \"\"\"\n",
    "    Gets the pairs of [dq_dt, dp_dt]\n",
    "    \"\"\"\n",
    "    deriv_pairs = []\n",
    "    for h_hat in h_hats:\n",
    "        dpdq = h_hat[0] * torch.tensor([-1.0, 1.0]).to(\"cuda\")\n",
    "        dqdp = torch.flip(dpdq, dims=[0])\n",
    "        deriv_pairs.append(dqdp)\n",
    "    return deriv_pairs\n",
    "\n",
    "\n",
    "deriv_pairs = get_deriv_pairs(h_hats)\n",
    "print(deriv_pairs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "445c55ce-58f3-4619-aff6-e5a95e17c15f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_time_derivatives(model, x):\n",
    "    \"\"\"\n",
    "    Computes time derivatives [dq/dt, dp/dt] for a batch of inputs.\n",
    "    x: Tensor of shape (Batch_Size, 2)\n",
    "    \"\"\"\n",
    "    # 1. Forward Pass to get Energy\n",
    "    H_hat = model(x)\n",
    "    print('\\n\\n==============H_hat==================')\n",
    "    print(H_hat)\n",
    "    \n",
    "    # 2. Vectorized Gradient Calculation\n",
    "    # We sum() the energy to get a scalar, but because samples are independent,\n",
    "    # the gradients separate out perfectly per row.\n",
    "    grads = torch.autograd.grad(H_hat.sum(), x, create_graph=True)[0]\n",
    "    print('\\n\\n==============grads==================')\n",
    "    print(grads)\n",
    "    \n",
    "    # grads is now shape (Batch, 2) -> [dH/dq, dH/dp]\n",
    "    \n",
    "    # 3. The Symplectic Swap (Hamilton's Eqs)\n",
    "    # dq/dt =  dH/dp\n",
    "    # dp/dt = -dH/dq\n",
    "    \n",
    "    dH_dq = grads[:, 0].unsqueeze(1)\n",
    "    dH_dp = grads[:, 1].unsqueeze(1)\n",
    "    \n",
    "    return torch.cat([dH_dp, -dH_dq], dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "99672fc1-f365-491b-a586-b0755db972da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "==============H_hat==================\n",
      "tensor([[0.0821],\n",
      "        [0.0837],\n",
      "        [0.0848]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "\n",
      "\n",
      "==============grads==================\n",
      "tensor([[-0.0101, -0.0109],\n",
      "        [-0.0052, -0.0035],\n",
      "        [ 0.0028, -0.0085]], device='cuda:0', grad_fn=<MmBackward0>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0109,  0.0101],\n",
       "        [-0.0035,  0.0052],\n",
       "        [-0.0085, -0.0028]], device='cuda:0', grad_fn=<CatBackward0>)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_model_time_derivatives(hnn_model, init_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "59d6a79a-4e4f-40c7-9410-700d3f40e8b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.tensor([[-0.0101, -0.0109],\n",
    "        [-0.0052, -0.0035],\n",
    "        [ 0.0028, -0.0085]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "aac0a305-46c5-4437-90ca-e42cafe2fd07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0101, -0.0109],\n",
       "        [-0.0052, -0.0035],\n",
       "        [ 0.0028, -0.0085]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "472a2184-4dc0-4eb0-a5b0-8ce3f3e58af5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0109],\n",
       "        [-0.0035],\n",
       "        [-0.0085]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[:, 1].unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7b7ec7c-0e9f-4b76-acd4-85ede86f8e4a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
